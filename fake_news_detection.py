# -*- coding: utf-8 -*-
"""Fake news detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1phu0yAd5dONCPnPIMqZCFVY8lDAJ4BTT
"""

import numpy as np
import pandas as pd
import itertools
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

# This pulls the data

file_id = '1soU7OGgejkFmz6vIxEXAGJAVg-1xeN0A'
url = f'https://drive.google.com/uc?id=1soU7OGgejkFmz6vIxEXAGJAVg-1xeN0A'

df = pd.read_csv(url)
print("Data loaded successfully from Google Drive!")

print(df.head())
df.shape

labels=df.label  # getting labels from dataframe
labels.head()

# slitting data into training and testing sets
# use a test_size 30% of the data will be held back for testing
x_train,x_test,y_train,y_test=train_test_split(df['text'], labels, test_size=0.3, random_state=45) # random_state=45 ensures the split is the same every time the code runs, for reproducibility

# Instantiate the TF-IDF Vectorizer
tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7) # stop_words='english tells the vectorizer to ignore common English words.
                                                                   # max_df=0.7 ignores words that appear in more than 70% of the dataset
tfidf_train=tfidf_vectorizer.fit_transform(x_train)  # Fit Learns the vocabulary and calculates the IDF
tfidf_test=tfidf_vectorizer.transform(x_test) # Transform Converts the text documents into numerical TF-IDF vectors

# Initialize a Classifier
pas_ag_cls=PassiveAggressiveClassifier(max_iter=50) # max_iter=50 sets the maximum number of passes over the training data
pas_ag_cls.fit(tfidf_train,y_train) # Fit the classifier to the training data (features and labels)

y_pred=pas_ag_cls.predict(tfidf_test) # Use the trained model to predict the class labels for test features
model_accuracy=accuracy_score(y_test,y_pred) # checking accuracy of model
print(f'Accuracy: {round(model_accuracy*100,2)}%')

# Build confusion matrix for evaluation
confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])